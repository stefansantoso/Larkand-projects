{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen, Request\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_redirects(job_url):\n",
    "  try:\n",
    "    req = Request(job_url, headers={'User-Agent' : \"Magic Browser\"})\n",
    "    return urlopen(req)\n",
    "  except urllib.error.HTTPError as e:\n",
    "    if e.code == 429:\n",
    "      time.sleep(5);\n",
    "      return resolve_redirects(job_url)\n",
    "    raise\n",
    "    \n",
    "def data_finder(alist):\n",
    "  res = [x for x in alist if x != None]\n",
    "  res = res[0]\n",
    "  res = res.text.strip().split('\\n')[0]\n",
    "  return res.strip()\n",
    "\n",
    "def remove_blanks(alist):\n",
    "  res = [x for x in alist if x != '']\n",
    "  return res\n",
    "\n",
    "def data_find(alist):\n",
    "  res = [x for x in alist if x != None]\n",
    "  res = res[0]\n",
    "  res = res.text.strip().split('\\n')\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_page_data(keys):\n",
    "  keywords = keys.replace(' ','+')\n",
    "  url = 'https://www.jobstreet.com.sg/en/job-search/job-vacancy.php?key={}'.format(keywords)\n",
    "  req = Request(url, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "  data = urlopen(req)\n",
    "  soup = BeautifulSoup(data)\n",
    "  jobs_num = soup.find(lambda tag: tag.get('id') == 'job_count_range').text.split(' ')[4]\n",
    "  if ',' in jobs_num:\n",
    "    jobs_count = int(jobs_num.split(',')[0])*1000 + int(jobs_num.split(',')[1])\n",
    "  else:\n",
    "    jobs_count = int(jobs_num)\n",
    "  jobs_count = math.ceil(jobs_count)\n",
    "  return jobs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_job_links(keys, page_count):\n",
    "  keywords = keys.replace(' ','+')\n",
    "  job_links = []\n",
    "  for i in range(page_count):\n",
    "    page = i+1\n",
    "    print('blashf'+str(page))\n",
    "    url = 'https://www.jobstreet.com.sg/en/job-search/job-vacancy.php?key={}&pg={}'.format(keywords, page)\n",
    "    req = Request(url, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "    data = urlopen(req)\n",
    "    soup = BeautifulSoup(data)\n",
    "    try:\n",
    "      first = soup.find_all(lambda tag: tag.name == 'div' and tag.get('id') == 'job_listing_panel')[0]\n",
    "      second = first.find_all(lambda tag: tag.name == 'a'and tag.get('class') == ['position-title-link'])\n",
    "      for job in second:\n",
    "        job_links.append(job.get('href'))\n",
    "    except:\n",
    "      pass\n",
    "  job_links = list(filter(lambda a: a != 'https://www.jobstreet.com.sg/en/job/1', job_links))\n",
    "  return job_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_job_data(job_url):\n",
    "  data = resolve_redirects(job_url)\n",
    "  soup = BeautifulSoup(data)\n",
    "  first = [x for x in soup.find_all('div') if x.get('class')== ['panel', 'panel-clean']]\n",
    "  if first != []:\n",
    "    company_name = data_finder([x.find(lambda tag: tag.get('id') == 'company_name') for x in first])\n",
    "    position_title = data_finder([x.find(lambda tag: tag.get('id') == 'position_title') for x in first])\n",
    "    #print(company_name)\n",
    "    try:\n",
    "      years_of_experience = data_finder([x.find(lambda tag: tag.get('id') == 'years_of_experience') for x in first])\n",
    "    except:\n",
    "      years_of_experience = None\n",
    "      pass\n",
    "\n",
    "    try:\n",
    "      if soup.find(lambda tag: tag.get('id') == 'single_work_location'):\n",
    "        job_location = data_finder([x.find(lambda tag: tag.get('id') == 'single_work_location') for x in first])\n",
    "      else:\n",
    "        job_location = data_finder([x.find(lambda tag: tag.get('id') == 'multiple_work_location_list') for x in first])\n",
    "    except:\n",
    "      job_location = None\n",
    "      pass\n",
    "\n",
    "\n",
    "    job_desc = remove_blanks(data_find([x.find(lambda tag: tag.get('id') == 'job_description') for x in first]))\n",
    "    job_desc = '.'.join(job_desc)\n",
    "\n",
    "    try:\n",
    "      address = data_finder([x.find(lambda tag: tag.get('id') == 'address') for x in first])\n",
    "    except:\n",
    "      address = None\n",
    "      pass\n",
    "\n",
    "\n",
    "    try:\n",
    "      company_size = data_finder([x.find(lambda tag: tag.get('id') == 'company_size') for x in first])\n",
    "    except:\n",
    "      company_size = None\n",
    "      pass\n",
    "    try:\n",
    "      company_industry = data_finder([x.find(lambda tag: tag.get('id') == 'company_industry') for x in first])\n",
    "    except:\n",
    "      company_industry = None\n",
    "      pass\n",
    "    try:\n",
    "      avg_processing_time = data_finder([x.find(lambda tag: tag.get('class') == ['align-normal']) for x in first])\n",
    "    except:\n",
    "      avg_processing_time = None\n",
    "      pass\n",
    "    try:\n",
    "      post_date = data_finder([x.find(lambda tag: tag.get('id') == 'posting_date') for x in first]).replace('Advertised: ','')\n",
    "    except:\n",
    "      post_date = None\n",
    "      pass\n",
    "    try:\n",
    "      close_date = data_finder([x.find(lambda tag: tag.get('id') == 'closing_date') for x in first]).replace('Closing on ','')\n",
    "    except:\n",
    "      close_date = None\n",
    "      pass\n",
    "    try:\n",
    "      ea_reg = data_finder([x.find(lambda tag: tag.get('id') == 'ea_registration_id') for x in first])\n",
    "    except:\n",
    "      ea_reg = None\n",
    "      pass\n",
    "\n",
    "\n",
    "    try:\n",
    "      company_overview = remove_blanks([x.strip() for x in [x for x in first if x.find(lambda tag: tag.get('id') == 'company_overview')][0].text.split('\\n')])\n",
    "      company_overview = list(filter(lambda a: a not in ['COMPANY OVERVIEW', ' COMPANY OVERVIEW'], company_overview))[0]\n",
    "    except:\n",
    "      company_overview = ''\n",
    "\n",
    "    dd = {'company_name' : company_name,\n",
    "          'position_title' : position_title,\n",
    "          'years_of_experience' : years_of_experience,\n",
    "          'job_location' : job_location,\n",
    "          'job_desc' : job_desc,\n",
    "          'address' : address,\n",
    "          'company_size' : company_size,\n",
    "          'company_industry' : company_industry,\n",
    "          'avg_processing_time' : avg_processing_time,\n",
    "          'post_date' : post_date,\n",
    "          'close_date' : close_date,\n",
    "          'ea_reg' : ea_reg,\n",
    "          'company_overview' : company_overview}\n",
    "  else:\n",
    "    return None\n",
    "  return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_parser(keys):\n",
    "  page = get_first_page_data(keys)\n",
    "  job_links = get_all_job_links(keys, page)\n",
    "  all_data = []\n",
    "  for i in job_links:\n",
    "    all_data.append(create_job_data(i))\n",
    "  return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blashf1\n",
      "blashf2\n",
      "blashf3\n",
      "blashf4\n",
      "blashf5\n",
      "\n",
      "103.84067630767822\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "all_jobs = main_parser('')\n",
    "all_jobs = [x for x in vv if x != None]\n",
    "end = time.time()\n",
    "print('')\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resolve_redirects('https://www.jobstreet.com.sg/en/job/managerassistant-manager-7506806?fr=21&searchRequestToken=9211de50-6a37-4bdd-b9b9-60806428d234&sectionRank=1')\n",
    "soup = BeautifulSoup(data)\n",
    "first = [x for x in soup.find_all('div') if x.get('class')== ['panel', 'panel-clean']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
